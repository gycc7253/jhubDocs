helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml
helm history jhub -n jhub --kube-context mykubes.k8s.local
kubectl get services --namespace jhub
vim config_multi.yaml
helm history jhub -n jhub --kube-context mykubes.k8s.local
kubectl get pods --namespace jhub
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml
kubectl get services --namespace jhub
vim config_multi.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml
kubectl get services --namespace jhub
kubectl get pods --namespace jhub
helm list --all-namespaces -a
helm history jhub -n jhub --kube-context mykubes.k8s.local
vim config_multi.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml
helm history jhub -n jhub --kube-context mykubes.k8s.local
vim config_multi.yaml
helm list 
helm list --namspace jhub
helm list --namespace jhub
helm history jhub -n jhub --kube-context mykubes.k8s.local
kubectl get services --namespace jhub
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=v0.10.6 --values config_multi.yamlhe
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=v0.10.6 --values config_multi.yaml
kubectl --namespace=jhub get pod
kubectl get services --namespace jhub
vim config_multi.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=v0.10.6 --values config_multi.yaml
kubectl get services --namespace jhub
ls
vim hub_pdb.yaml
vim proxy_pdb.yaml
vim config.yaml
helm history jhub -n jhub --kube-context mykubes.k8s.local
vim config.yaml
vim config_multi.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml
kubectl get services --namespace jhub
vim config_multi.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml
helm history jhub -n jhub --kube-context mykubes.k8s.local
kubectl get services --namespace jhub
kubectl get pods --namespace jhub
kubectl get services --namespace jhub
kubectl get pods --namespace jhub
vim config_multi.yaml
vim config.yaml
diff config.yaml config_multi.yaml
ls
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config.yaml
helm history jhub -n jhub --kube-context mykubes.k8s.local
vim config.yaml
ls
vim config.yaml
ls
ls -a
rm .config.yaml.swp
ls
ls -a
vim config.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config.yaml
ls
vim config.yaml
ls
vim config.yaml
kubectl get services --namespace jhub
kubectl get pods --namespace jhub
vim config.yaml
vim config_multi.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config[A.yaml
kubectl get services --namespace jhubhelm list --all-namespaces -a
helm list --all-namespaces -a
helm history jhub -n jhub --kube-context mykubes.k8s.local
vim config_multi.yaml
kubectl get pods --namespace jhub
vim config_multi.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml
helm list --all-namespaces -a
helm history jhub -n jhub --kube-context mykubes.k8s.local
kubectl get services --namespace jhub
vim config.yaml
openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -days 365
ls
vim key.pem
ls -l
rm key.pem
ls
openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -days 365
ls
vim key.pem
cat key.pem
ls
vim cert.pem
ls
mkdir jhubCert
ls
cd jhubCert
ls
sudo openssl req -new -x509 -sha256 -days 365 -nodes -out /etc/ssl/localcerts/jhub.pem -keyo
sudo openssl req -new -x509 -sha256 -days 365 -nodes -out jhub.pem -keyout jhub.key
ls
vim jhub.key
cd ..
ls
vim jhub.key
vim config.yaml
ls
vim config.yaml
sudo vim config.yaml
ls
ls jhubCert
vim jhub.pem
vim jhubCert/jhub.pem
cd jhubCert
ls
mv jhub.pem jhub.cert
cd ..
ls
vim config.yaml
sudo vim config.yaml
vim config.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config.yaml
kubectl get services --namespace jhub
helm history jhub -n jhub --kebe-context mykubes.k8s.local
helm history jhub -n jhub --kube-context mykubes.k8s.local
helm list
helm list -a
helm list --namespace jhub
ls
vim jhubCert/jhub.cert
ls -l 
ls -l jhubCert
vim config.yaml
kubectl get pods --namespace jhub
vim config.yaml
vim config_multi.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml
kubectl get services --namespace jhub
kubectl get pods --namespace jhub
vim config.yaml
vim config_multi.yaml
helm history jhub -n jhub --kube-context mykubes.k8s.local
helm list --all-namespaces -a
helm rollback jhub 15 -n jhub --kube-context mykubes.k8s.local
helm list --all-namespaces -a
kubectl get pods --namespace jhub
vim config_multi.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml
helm list --all-namespaces -a
helm history jhub -n jhub --kube-context mykubes.k8s.local
kubectl get pods --namespace jhub
helm rollback jhub 15 -n jhub --kube-context mykubes.k8s.local
kubectl get pods --namespace jhub
vim config_multi.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml
kubectl get pods --namespace jhub
vim config_multi.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml
kubectl get pods --namespace jhub
kubectl get services --namespace jhub
kubectl get pods --namespace jhub
vim config_multi.yaml
helm history jhub -n jhub --kube-context mykubes.k8s.local
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml1
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml
kubectl get pods --namespace jhub
kubectl get services --namespace jhub
vim config_multi.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml
kubectl get services --namespace jhub
vim config_multi.yaml
kubectl get pods --namespace jhub
vim config_multi.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml
kubectl get pods --namespace jhub
kubectl get services --namespace jhub
vim config_multi.yaml
exit
cat /etc/exports 
ssh ec2-54-169-224-20.ap-southeast-1.compute.amazonaws.com
sudo nano /etc/exports 
sudo exportfs -av
sudo systemctl restart nfs-kernel-server
ssh ec2-54-169-224-20.ap-southeast-1.compute.amazonaws.com
cat /etc/exports 
kubectl get pod --namespace jhub
df -h
helm list
helm
helm list --namespace jhub
helm show --namespace jhub
helm show --namespace jhub all
helm show all --namespace jhub 
helm show all jhub --namespace jhub 
helm show all jupyterhub-0.10.6 --namespace jhub 
helm repo update
helm show all jupyterhub-0.10.6 --namespace jhub 
helm show all jupyterhub --namespace jhub 
helm show  jupyterhub --namespace jhub 
helm
helm status
helm status jhub
helm show all jupyterhub-0.10.6 --namespace jhub 
helm show all jhub --namespace jhub 
helm show all --namespace jhub 
helm list --namespace jhub
kubectl get storageclass
ls
cat config.yaml 
cp config.yaml config_multi.yaml 
nano config_multi.yaml 
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml 
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml -b
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml -v
helm
helm upgrade
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml --debug
helm status jhub
helm status
helm list
helm
helm list --namespace jhub
helm status
helm status jhub
helm status jhub --namespace jhub
kubectl --namespace=jhub get pod
helm status jhub --namespace jhub
kubectl --namespace=jhub get pod
helm status jhub --namespace jhub
helm list --all-namespaces -a
kubectl --namespace=jhub get pod
helm list --all-namespaces -a
helm rollback jhub 12
helm rollback jhub 12 -n jhub
helm list --all-namespaces -a
#helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml -debug
kubectl --namespace=jhub get pod
kubectl get pods --show-all=true
kubectl delete pods hook-image-puller-4rx89
kubectl --namespace=jhub get pod
kubectl delete pods hook-image-puller-4rx89 --namespace=jhub
kubectl --namespace=jhub get pod
#helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml -debug
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml -debug
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml --debug
kubectl describe pods
kubectl describe pods --namespace jhub
kubectl --namespace=jhub get pod
helm list --all-namespaces -a
helm rollback jhub 12 -n jhub
nano config_multi.yaml 
helm list --all-namespaces -a
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml --debug
kubectl --namespace=jhub get pod
ls /home
history | grep ssh
ssh ec2-13-229-61-165.ap-southeast-1.compute.amazonaws.com
env
helm
helm env
df -h
ls .cache/helm
ls .cache/helm/repository/
ls .local/share/helm
ls .local/share/
cat .config/helm/repositories.yaml 
kubectl
kubectl config
kubectl config current-context
kubectl config view
history | grep ssh
ssh ec2-13-229-61-165.ap-southeast-1.compute.amazonaws.com
kubectl --namespace=jhub get pod
ssh ec2-13-229-61-165.ap-southeast-1.compute.amazonaws.com
kubectl --namespace=jhub get pod
kubectl config view
ssh ec2-13-229-61-165.ap-southeast-1.compute.amazonaws.com
kubectl --namespace=jhub get pod
helm list --all-namespaces -a
ls
nano config_multi.yaml 
helm list --all-namespaces -a
kops rolling-update cluster mykubes.k8s.local
kops rolling-update cluster mykubes.k8s.local --yes
ls
#helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml --debug
#helm rollback jhub 12 -n jhub
helm list --all-namespaces -a
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml --debug
helm rollback jhub 17 -n jhub
kops rolling-update cluster mykubes.k8s.local --yes
kops rolling-update cluster 
kops rolling-update 
kops rolling-update cluster --yes --force
kops get instasncegroups
kops get instancegroups
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml --debug
helm rollback jhub 17 -n jhub
kubectl --namespace=jhub get pod
kops get instancegroups
kubectl --namespace=jhub get pod
nano config_multi.yaml 
kubectl --namespace=jhub get pod
kops get instancegroups
helm list --all-namespaces -a
kubectl --namespace=jhub get pod
helm list --all-namespaces -a
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi.yaml --debug
kubectl --namespace=jhub get svc proxy-public
kubectl --namespace=jhub get pod
helm list --all-namespaces -a
kops get instancegroups
kops rolling-update cluster --yes 
kubectl get poddisruptionbudgets

kubectl get poddisruptionbudgets hub -o yaml
kubectl get poddisruptionbudgets hub -o yaml --namespace jhub
kubectl get poddisruptionbudgets hub -o yaml --namespace jhub >> hub_pdb.yaml
kubectl get poddisruptionbudgets proxy -o yaml --namespace jhub >> hub_pdb.yaml
kubectl get poddisruptionbudgets user-placeholder -o yaml --namespace jhub >> hub_pdb.yaml
rm hub_pdb.yaml 
kubectl get poddisruptionbudgets hub -o yaml --namespace jhub >> hub_pdb.yaml
kubectl get poddisruptionbudgets proxy -o yaml --namespace jhub >> proxy_pdb.yaml
kubectl get poddisruptionbudgets user-placeholder -o yaml --namespace jhub >> placeholder_pdb.yaml
nano hub_pdb.yaml 
kubectl get nodes
kubectl describe node ip-172-20-47-118.ap-southeast-1.compute.internal
kubectl get events
kubectl describe node ip-172-20-47-118.ap-southeast-1.compute.internal
kubectl get nodes
kubetctl ip-172-20-47-118.ap-southeast-1.compute.internal uncordon
kubectl ip-172-20-47-118.ap-southeast-1.compute.internal uncordon
kubectl uncordon ip-172-20-47-118.ap-southeast-1.compute.internal 
kubectl get nodes
kops rolling-update cluster --yes 
kubectl --namespace=jhub get pod
kubectl
kubectl rollout reboot
kubectl rollout restart
kubectl rollout restart --namespace jhub
kubectl cluster-info
kubectl cluster-info dump
kubectl get deployments
kubectl get deployments --namespace jhub
kubectl rollout restart deployment
kubectl get deployments --namespace jhub
kubectl rollout restart deployment user-scheduler
kubectl rollout restart deployment proxy
kubectl rollout restart deployment --replicas 1
kubectl rollout restart deployment --replica 1
kubectl rollout restart deployment --replicas=1
kubectl rollout restart --help
kubectl rollout restart deployment/hub
kubectl rollout restart deployment/proxy
kubectl rollout restart deployment/proxy --namespace jhub
kubectl get deployments --namespace jhub
kubectl rollout restart deployment/proxy --namespace jhub
kubectl --namespace=jhub get pod
kubectl rollout restart deployment/user-scheduler --namespace jhub
kubectl rollout restart deployment/hub --namespace jhub
kubectl --namespace=jhub get pod
helm list --all-namespaces -a
kubectl --namespace=jhub get svc proxy-public
kubectl --namespace=jhub get pod
kops get instancegroups
kubectl --namespace=jhub get pod
kubectl --namespace=jhub get svc proxy-public
kubectl --namespace=jhub get pod
ls -l
vim config_multi.yaml
ls
kubectl get services --namespace jhub
kops export kubecfg --admin --kubeconfig ~/workspace/kubeconfig --state=s3://mykubesbucket
kubectl get services --namespace jhub
vim -h
:q
vim -R config_multi.yaml
cp config_multi.yaml config_multi_dummy.yaml
vim config_multi_dummy.yaml
pip install jupyterhub-dummyauthenticator
kubectl get services --namespace jhub
kubectl get pods --namespace jhub
helm history jhub -n jhub --kube-context mykubes.k8s.local
vim config_multi_dummy.yaml
helm history jhub -n jhub --kube-context mykubes.k8s.local
vim config_multi_dummy.yaml
ls
helm history jhub -n jhub --kube-context mykubes.k8s.local
kubectl get pods --namespace jhub
helm history jhub -n jhub --kube-context mykubes.k8s.local
ls
vim config_multi_dummy.yaml
helm history jhub -n jhub --kube-context mykubes.k8s.local
vim config_multi_dummy.yaml
helm history jhub -n jhub --kube-context mykubes.k8s.local
vim config_multi_dummy.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values config_multi_dummy.yaml
helm history jhub -n jhub --kube-context mykubes.k8s.local
vim config_multi_dummy.yaml
ls
vim config_multi.yaml
cp config_multi.yaml config_multi_github.yaml
vim config_multi_github.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values config_multi_github.yaml
vim config_multi_github.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values config_multi_github.yaml
helm history jhub -n jhub --kube-context mykubes.k8s.local
kubectl get services --namespace jhub
vim config_multi_github.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values config_multi_github.yaml
helm history jhub -n jhub --kube-context mykubes.k8s.local
kubectl get pods --namespace jhub
kubectl get services --namespace jhub
vim config_multi_github.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values config_multi_github.yaml
kubectl get services --namespace jhub
vim config_multi_github.yaml
ls
mkdir configs
mv config.yaml configs/config.yaml
mv config_multi.yaml configs/config_multi.yaml
ls
mv config_multi_github.yaml configs/config_multi_github.yaml
mv config_multi_dummy.yaml configs/config_multi_dummy.yaml
ls
ls jhubCert
mkdir jhubCert/oldCert
mv key.pem jhubCert/oldCert/key.pem
mv cert.pem jhubCert/oldCert/cert.pem
ls
ls configs
cp configs/config_multi.yaml configs/config_multi_pam.yaml
vim configs/config_multi_pam.yaml
ls
vim configs/config_multi_github.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_github.yaml
kubectl get services --namespace jhub
vim configs/config_multi_github.yaml
kubectl get pods --namespace jhub
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_github.yaml
vim configs/config_multi_github.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_github.yaml
helm history jhub -n jhub --kube-context mykubes.k8s.local
vim configs/config_multi_github.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_github.yaml
kubectl get services --namespace jhub
vim configs/config_multi_github.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_github.yaml
vim configs/config_multi_github.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_github.yaml
kubectl get services --namespace jhub
vim configs/config_multi_github.yaml
ls
cd configs
ls
cd ..
vim config_multi_github.yaml
vim configs/config_multi_github.yaml
ls
kubectl get services --namespace jhub
kubectl get pods --namespace jhub
ls configs/
vim configs/config_multi_pam.yaml
less /etc/passwd
cat /etc/passwd
cat /etc/shadow
sudo cat /etc/shadow
sudo useradd gycc7253
sudo passwd gycc7253
cat /etc/shadow
sudo passwd gycc7253
sudo cat /etc/shadow
sudo cat /etc/shadow | grep gycc
openssl passwd -6 -salt 9jbndEfm
openssl -h
openssl
openssl --help
openssl help
openssl passwd help
vim configs/config_multi_pam.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_pam.yaml
kubectl get services --namespace jhub
kubectl get pods --namespace jhub
helm history jhub -n jhub --kube-context mykubes.k8s.local
kubectl get pods --namespace jhub
kubectl get services --namespace jhub
cat /etc/passwd | grep gyxx
cat /etc/passwd | grep gycc
ssh ec2-13-250-54-242.ap-southeast-1.compute.amazonaws.com
ls\
ls
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_pam.yaml
sudo passwd gycc7253
ssh ec2-13-212-173-12.ap-southeast-1.compute.amazonaws.com
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_pam.yaml
kubectl get services --namespace jhub
kubectl get pods --namespace jhub
vim configs/config_multi_pam.yaml
vim configs/config_multi_dummy.yaml
vim configs/config_multi_github.yaml
cat /etc/shadow
cat /etc/shadow sudo
sudo cat /etc/shadow
ssh ec2-13-250-54-242.ap-southeast-1.compute.amazonaws.com
ssh ec2-13-212-173-12.ap-southeast-1.compute.amazonaws.com
ls
vim configs/config_multi_pam.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_pam.yaml
kubectl get services --namespace jhub
kubectl get pods --namespace jhub
sudo cat /etc/shadow
sudo useradd user1
sudo passwd user1
sudo cat /etc/shadow
vim configs/config_multi_pam.yaml
ls
sudo useradd user3
sudo passwd user3
ls
ssh ec2-13-250-54-242.ap-southeast-1.compute.amazonaws.com.
ssh ec2-13-250-54-242.ap-southeast-1.compute.amazonaws.com
ec2-13-212-173-12.ap-southeast-1.compute.amazonaws.com
ssh ec2-13-212-173-12.ap-southeast-1.compute.amazonaws.com
ls
sudo cat /etc/shadow
sudo useradd user2
sudo passwd user2
kubectl get services --namespace jhub
vim configs/config_multi_pam.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_pam.yaml
vim configs/config_multi_pam.yaml
sudo passwd user1
sudo passwd user3
ssh ec2-13-250-54-242.ap-southeast-1.compute.amazonaws.com
ls
vim configs/config_multi_pam.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_pam.yaml
sudo passwd
ls
ssh ec2-13-250-54-242.ap-southeast-1.compute.amazonaws.com
ls
vim configs/config_multi_pam.yaml
sudo cat /etc/shadow
vim configs/config_multi_pam.yaml
ls
vim configs/config_multi_pam.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_pam.yaml
vim configs/config_multi_pam.yaml
ls
vim configs/config_multi_pam.yaml
ls
ssh ec2-13-250-54-242.ap-southeast-1.compute.amazonaws.com
kubectl --namespace jhub logs
kubectl --namespace jhub get pods
kubectl --namespace jhub logs hub-5cbdc74bc5-nz6x8
ls
vim configs/config_multi_pam.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_pam.yaml
kubectl --namespace jhub logs hub-5cbdc74bc5-nz6x8
kubectl get pods --namespace jhub
helm history jhub -n jhub --kube-context mykubes.k8s.local
kubectl get services --namespace jhub
vim configs/config_multi_pam.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_pam.yaml
kubectl --namespace jhub logs hub-6bb45b6674-rqxxw
vim /etc/security/user
vim /etc/security
ls /etc/security
vim /etc/security/pam_env.conf
vim /etc/jupyterhub
vim /etc/jupyterhub/secret/values.yaml
ls
vim configs/config_multi_dummy.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_dummy.yaml
ls
helm history jhub -n jhub --kube-context mykubes.k8s.local
vim configs/config_multi_pam.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_pam.yaml
vim configs/config_multi_dummy.yaml
kubectl get pods --namespace jhub
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_dummy.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_pam.yaml
kubectl get pods --namespace jhub
kubectl --namespace jhub logs hub-7b77b97f8d-hxjs5
id
vim configs/config_multi_pam.yaml
kubectl config set-context $(kubectl config current-context)     --namespace=jhub
kubectl get pods
kops export kubecfg --admin --kubeconfig ~/workspace/kubeconfig --state=s3://mykubesbucket
kubectl get pods
kops export kubecfg --admin
kubectl get pods
kubectl get services
ls
vim configs/config_multi_pam.yaml
helm history jhub -n jhub --kube-context mykubes.k8s.local
ps -u root
ps
ps -help
ps --help
ps --help all
top -u root
top
ssh ec2-13-250-54-242.ap-southeast-1.compute.amazonaws.com
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values configs/config_multi_pam.yaml
kubectl get services
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_pam.yaml
kubectl get services
vim configs/config_multi_pam.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_pam.yaml
helm history jhub -n jhub --kube-context mykubes.k8s.local
kubectl get services
ssh ec2-13-250-54-242.ap-southeast-1.compute.amazonaws.com
kubectle get pods --namespace jhub
kubectl get pods --namespace jhub
kubectl logs hub-68646f47d7-qvzjc
sudo cat /etc/shadow
ls
ssh ec2-13-250-54-242.ap-southeast-1.compute.amazonaws.com
vim configs/config_multi_pam.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_pam.yaml
sudo cat /etc/shadow
kubectl get services
kubectl get pods
vim configs/config_multi_pam.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_pam.yaml
kubectl get pods 
kubectl get services
kubectl get pods 
vim configs/config_multi_pam.yaml
kubectl logs hub-59dffd68d9-5nn4q
vim configs/config_multi_pam.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_pam.yaml
kubectl get pods 
kubectl get services
kubectl logs hub-5dc5cff78-4q9jw
find . --name auth.py
find . -name auth.py
find / -name auth.py
ls /
find /etc -name auth.py
find /home -name auth.py
ls /mnt
ls /mnt/nfs_share
ls /lib
find / -name jupyterhub
vim /usr/local/lib/python3.8/dist-packages/jupyterhub/auth.py
vim configs/config_multi_pam.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_pam.yaml
kubectl get pods 
kubectl get services
kubectl logs hub-fbb6bb8d5-x8zvq
logs
bash logs
vim configs/config_multi_pam.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_pam.yaml
kubectl get pods
kubectl logs hub-888688664-sxf4b
vim configs/config_multi_pam.yaml
ls
vim configs/config_multi_pam.yaml
ls configs
ls configs -a
rm configs/.config_multi_pam.yaml.swp
ls
kubectl get pods
kubectl logs hub-888688664-sxf4b
ls
ls jhubCert
vim configs/config_multi_pam.yaml
kubectl get pods
kubectl get services
vim configs/config_multi_pam.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_pam.yaml
kubectl get pods
kubectl logs hub-588c9cd7c6-9wzkd
kubectl get services
vim configs/config_multi_pam.yaml
kubectl logs hub-588c9cd7c6-9wzkd
vim configs/config_multi_pam.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_pam.yaml
kubectl get pods
kubectl logs hub-555dccb978-hch4x.
kubectl logs hub-555dccb978-hch4x
kubectl get services
vim configs/config_multi_pam.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_pam.yaml
kubectl get pods
kubectl get services
exit
ls
kops get cluster
kops get mykubes.k8s.local
kops get nodes-ap-southeast-1a
kops get ig nodes-ap-southeast-1a
kops get ig
kops edit ig nodes-ap-southeast-1a
kops update cluster
kops update cluster --yes
kops rolling-update cluster --yes
kubectl get nodes
kops export kubecfg --admin --kubeconfig ~/workspace/kubeconfig --state=s3://mykubesbucket
kops export kubecfg --admin
kops rolling-update cluster --yes
kops edit ig nodes-ap-southeast-1a
kubectl get nodes
kops rolling-update --help
kops rolling-update cluster --instance-group nodes-ap-southeast-1a --yes
kops update ig nodes-ap-southeast-1a
kops udpate cluster mykubes.k8s.local 
kops update cluster mykubes.k8s.local 
kubectl get services
vim configs/config_multi_dummy.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_dummy.yaml
kubectl get pods
ls
ls /hub
ls
ssh ec2-13-250-54-242.ap-southeast-1.compute.amazonaws.com
ls /etc
exit
ls
kubectl get services
kops export kubecfg --admin --kubeconfig ~/workspace/kubeconfig --state=s3://mykubesbucket
kops export kubecfg --admin
kubectl get services
kops get cluster
kops get mykubes.k8s.local
kops get ig
kops edit ig nodes-ap-southeast-1a
kops get nodes
kubectl get nodes
kops edit ig nodes-ap-southeast-1a
kops update cluster
kops update cluster --yes
kops rolling-update cluster --yes
kubectl get nodes
kops get ig
kubectl get nodes
kops edit ig nodes-ap-southeast-1a
kops
kops describe nodes-ap-southeast-1a
kops
kubectl get nodes
kubectl get pods
kubectl get services
kubectl get pods
kubectl get services
vim configs/config_multi_dummy.yaml
kubectl get pods
ls configs
cp configs/config_multi_dummy.yaml configs/config_opt.yaml
vim configs/config_opt.yaml
kubectl get pods
vim configs/config_opt.yaml
kubectl get pods
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_opt.yaml
kubectl get services
kubectl get pods
kubectl get services
kubectl get pods
kubectl get services
kubectl get nodes
ls
vim configs/config_opt.yaml
kubectl get pods
vim configs/config_opt.yaml
kubectl get pods
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_opt.yaml
kubectl get pods
kubectl get nodes
kubectl describe node ip-172-20-47-164.ap-southeast-1.compute.internal
vim configs/config_opt.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_opt.yaml
vim configs/config_opt.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_opt.yaml
kubectl get pods
cat configs/config_opt.yaml
kubectl get nodes
vim configs/config_multi_dummy.yaml
vim configs/config_opt.yaml
kops get ig
kops edit ig nodes-ap-southeast-1a
kops update cluster
kops update cluster --yes
kops rolling-update cluster
kubectl get opds
kubectl get pods
kubectl get nodes --show-labels
ls
vim pod.yaml
kubectl apply -f pod.yaml
vim configs/config_opt.yaml
kubectl get pods
kubectl get pods -o wide
kubectl get nodes --show-labels
kubectl
kubectl apply
kubectl apply --help
kubectl
kubectl config
vim configs/config_opt.yaml
kubectl get pods
kubectl get services
kubectl get nodes
vim configs/config_opt.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_opt.yaml
kubectl get services
kubectl get nodes
kubectl get pods
vim configs/config_opt.yaml
kubectl get nodes
kubectl get pods
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_multi_dummy.yaml
kubectl get pods
kubectl get nodes
kubectl get pods
kops get ig
kubectl get nodes
kubectl describe node ip-172-20-63-192.ap-southeast-1.compute.internal
kubectl get pods
vim configs/config_opt.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_opt.yaml
kubectl get pods
kubectl get nodes
kubectl get pods
kubectl get nodes
kubectl get pods
vim configs/config_opt.yaml
helm version
kubectl version
kubectl api-versions
kubectl version
kubectl get pods
aws eks describe-cluster --name mykubes.k8s.local --query "cluster.identity.oidc.issuer" --output text
aws eks describe-cluster --name mykubes.k8s.local --query "cluster.identity.oidc.issuer" --output text --region ap-southeast-1a
kops get cluster
kops get ig
kops edit ig nodes-ap-southeast-1a
kops update cluster mykubes.k8s.local
kops update cluster mykubes.k8s.local --yes
kops version
kops get ig
ls
mkdir autoscaler
cd autoscaler
ls
git clone https://github.com/kubernetes/autoscaler.git
ls
cd autoscaler
ls
cd ..
rm -r autoscaler
ls
git clone https://github.com/kubernetes/autoscaler.git
ls
cd autoscaler
ls
vim ig-policy.json
aws iam create-policy --policy-name ig-policy --policy-document file://ig-policy.json
aws iam attach-role-policy --policy-arn arn:aws:iam::156688359548:policy/ig-policy --role-name nodes.demo.cloudchap.cf
aws iam attach-role-policy --policy-arn arn:aws:iam::156688359548:policy/ig-policy --role-name KubernetesIAMRole
kops get ig
kops edit ig nodes-ap-southeast-1a
ls
vim cluster-autoscaler-multi-asg.yaml
aws iam attach-role-policy --policy-arn arn:aws:iam::156688359548:policy/ig-policynodes-ap-southeast-1a
aws iam attach-role-policy --policy-arn arn:aws:iam::156688359548:policy/ig-policy --role-name nodes-ap-southeast-1a
vim cluster-autoscaler-multi-asg.yaml
ls /etc/ssl
cat cluster-autoscaler-multi-asg.yaml
vim /etc/ssl/certs/ca-bundle.crt
ls
vim /etc/ssl/certs/ca-bundle.crt
vim cluster-autoscaler-multi-asg.yaml
ls
cd ..
ls
cd autoscaler
ls
vim cluster-autoscaler-multi-asg.yaml
kubectl apply -f cluster-autoscaler-multi-asg.yaml
vim cluster-autoscaler-multi-asg.yaml
kubectl apply -f cluster-autoscaler-multi-asg.yaml
kubectl get pods
kubectl get pods -l app=cluster-autooscaler -n kube-system
kubectl get pods -l app=cluster-autooscaler -n mykubes.k8s.local
kubectl get pods -l app=cluster-autooscaler
kubectl get pods -l app=cluster-autooscaler -n jhub
kubectl get pods -l app=cluster-autoscaler -n kube-system
kubectl get pods -l app=cluster-autoscale
kubectl get pods -l app=cluster-autoscalet
kubectl get pods -l app=cluster-autoscaler
kubectl get pods
kubectl logs -f pod/cluster-autoscaler-5bf8f5ff56-wkngq -n kube-system
kubectl get pods -l app=cluster-autoscaler -n kube-system
vim cluster-autoscaler-multi-asg.yaml
kubectl apply -f cluster-autoscaler-multi-asg.yaml
kubectl logs -f pod/cluster-autoscaler-5bf8f5ff56-wkngq -n kube-system
kubectl get pods -l app=cluster-autoscaler -n kube-system
kubectl get pods -l cluster-autoscaler-5c8689c5f6-z5m7g -n kube-system
kubectl get pods -l cluster-autoscaler-5c8689c5f6-z5m7g
vim cluster-autoscaler-multi-asg.yaml
kubectl apply -f cluster-autoscaler-multi-asg.yaml
vim cluster-autoscaler-multi-asg.yaml
ls
kubectl get pods
kops export kubecfg --admin --kubeconfig ~/workspace/kubeconfig --state=s3://mykubesbucket
kops export kubecfg --admin
kubectl get pods
kubectl get ig
kops get ig
kops edit ig nodes-ap-southeast-1a
kops update cluster
kops update cluster --yes
kops rolling-update cluster
kops rolling-update cluster --yes
kops get ig
kops edit ig nodes-ap-southeast-1a
kops update cluster 
kops rolling-update cluster
kops rolling-update cluster --yes
kubectl get nodes
kops rolling-update cluster --yes
kops get ig
kops edit ig nodes-ap-southeast-1a
kops update cluster
kops update cluster --yes
kops rolling-update cluster
kubectl get nodes
kubectl get pods
vim configs/config_opt.yaml
kops get ig
kubectl get nodes
kops create ig spot-ig
kops get ig
kops get cluster
kops update cluster mykubes.k8s.local
kops update cluster mykubes.k8s.local --yes
kops rolling-update cluster
ls 
ls autoscaler
cd autoscaler
ls
vim ig-policy.json
aws iam
kops get ig
aws iam create-policy --policy-name ig-policy --policy-document file://ig-policy.json
aws list-policies
aws iam list-policies
aws iam list-roles
aws iam --help
aws help
aws iam
aws iam get-role ig-policy
aws iam get-role --role-name ig-policy
aws iam get-policy --role-name ig-policy
aws iam list-attached-role-policies
aws iam list--policies
aws iam list-policies
aws iam list-policies | grep ig-policy
kops get ig
kubectl get nodes
aws iam attach-role-policy --policy-arn arn:aws:iam::156688359548:policy/ig-policy --role-name xxx
kops edit ig spot-ig
ls
cd ..
ls
vim pod.yaml
cd autoscaler
ls
vim cluster-autoscaler-multi-asg.yaml
kops get ig
vim cluster-autoscaler-multi-asg.yaml
kubectl apply -f cluster-autoscaler-multi-asg.yaml
kubectl get pods -l app=cluster-autoscaler -n kube-system
kubectl get pods
ls
cd ..
ls
vim configs/config_opt.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_opt.yaml
kubectl get nodes
kubectl get pods
kubectl get services
kubectl get pods
ls
kubectl get pods
kubectl get services
kubectl get pods
kubectl get nodes
kubectl get pods
kubectl get services
vim configs/config_opt.yaml
kops get ig
kubectl get node
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_opt.yaml
kubectl get pods
kubectl get nodes
kubectl describe jupyter-user1.
kubectl describe jupyter-user1
kubectl describe pod jupyter-user1
kubectl get pods
vim configs/config_opt.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_opt.yaml
kubectl get pods
kubectl get services
kubectl get pods
kubectl get nodes
kubectl get pods
kubectl logs ip-172-20-59-219.ap-southeast-1.compute.internal
kops get ig
kubectl get pods -l app=cluster-autoscaler -n kube-system
kubectl get pods
kubectl logs nginx
kubectl describe nginx
kubectl describe pod nginx
kubectl get pods
kops validate cluster
ssh ec2-13-250-54-242.ap-southeast-1.compute.amazonaws.com
ls
ls autoscaler
ls
vim cluster-autoscaler-multi-asg.yaml
vim autoscaler/cluster-autoscaler-multi-asg.yaml
kubectl get pods
kubectl get nodes
kubectl get pods -l app=cluster-autoscaler -n kube-system
kubectl get pods -l app=cluster-autoscaler -n kube-system pod/cluster-autoscaler-59779757ff-xbdtt -n kube-system
kubectl logs -f pod/cluster-autoscaler-59779757ff-xbdtt -n kube-system
vim autoscaler/cluster-autoscaler-multi-asg.yaml
kubectl get services
kubectl get pods
ls
ls autoscaler
vim autoscaler/examples/cluster-autoscaler-multi-asg.yaml
kops version
kubectl version
kubectl get pods
vim autoscaler/cluster-autoscaler-multi-asg.yaml
kubectl get pods --output=wide
kubectl get nodes --show-labels
kops get ig
kops edit ig spot-ig
ls

aws eks describe-cluster --name <cluster_name> --query "cluster.identity.oidc.issuer" --output text
D
exit
aws eks describe-cluster --name mykubes.k8s.local --query "cluster.identity.oidc.issuer" --output text
aws eks describe-cluster --name mykubes.k8s.local --query "cluster.identity.oidc.issuer" --output text --region ap-southeast-1a
clear
ls
kubectl get nodes
kops get ig
kops edit ig spot-ig
kops update cluster
kops update cluster --yes
kops rolling-update cluster --yes
vim configs/config_opt.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_opt.yaml
kubectl get pods
kubectl get nodes
clear
vim configs/config_opt.yaml
kubectl get pods
kubectl logs jupyter-user3
kubectl logs pod jupyter-user3
kubectl logs jupyter-user2
vim configs/config_multi_github.yaml
exit
ls
kubectl get pods
kubectl get nodes --show-labels
kubectl label nodes ip-172-20-59-219.ap-southeast-1.compute.internal nodetype
kubectl label nodes ip-172-20-62-114.ap-southeast-1.compute.internal distype=ssd
kubectl get nodes --show-labels
ls
vim pod.yaml
kubectl get pods
kubectl drain nginx
kubectl delete pod nginx
kubectl get pods
vim configs/config_opt.yaml
kubectl label nodes ip-172-20-62-114.ap-southeast-1.compute.internal nodetype=awesome
kubectl get nodes
kubectl label nodes ip-172-20-59-219.ap-southeast-1.compute.internal nodetype=awesome
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_opt.yaml
kubectl get pods
kubectl get services
kubectl get service --all-namespaces
kubectl get pod -o wide
kops get cluster
kops get igkubectl get pods -l app=cluster-autoscaler -n kube-system
kubectl get nodes
kubectl get pods -l app=cluster-autoscaler -n kube-system
kops edit ig spot-ig
exit
kops get ig
kops edit ig spot-ig
kops edit ig nodes-ap-southeast-1a
kubectl get pods
kops get ig
kops edit ig spot-ig
exit
kops get ig
kubectl get pods
kops get ig 
kops edit ig spot-ig
kops update cluster
kops update cluster --yes
kops upgrade cluster
kops upgrade cluster --yes
kops update cluster mykubes.k8s.local
kops update cluster mykubes.k8s.local --yes
kops rolling-update cluster --yes
ls
cd autoscaler
ls
vim ig-policy.json
aws iam list-policy | grep ig-policy
aws iam list-policies | grep ig-policy
aws iam attach-role-policy --policy-arn arn:aws:iam::156688359548:policy/ig-policy --role-name spot-ig.mykubes.k8s.local
aws iam attach-role-policy --policy-arn arn:aws:iam::156688359548:policy/ig-policy --role-name masters.mykubes.k8s.local
aws iam attach-role-policy --policy-arn arn:aws:iam::156688359548:policy/ig-policy --role-name nodes.mykubes.k8s.local
aws iam attach-role-policy --policy-arn arn:aws:iam::156688359548:policy/ig-policy --role-name KubernetesIAMRole
kops get ig
kops edit ig nodes-ap-southeast-1a
kops edit ig spot-ig
ls
vim cluster-autoscaler-multi-asg.yaml
kubectl apply -f cluster-autoscaler-multi-asg.yaml
kubectl get pods -l app=cluster-autoscaler -n kube-system
kubectl get pods
kubectl get pods -l app=cluster-autoscaler -n kube-system
kubectl logs -f pod/cluster-autoscaler-69b696b7df-rb8l6 -n kube-system
kubectl logs -f pod/cluster-autoscaler-59779757ff-bfn7k -n kube-system
kubectl get pods
kubectl get pods -l app=cluster-autoscaler -n kube-system
kubectl get pods
vim configs/config_opt.yaml\
vim configs/config_opt.yaml
cd ..
vim configs/config_opt.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_opt.yaml
kubectl get pods
kubectl get pods -l app=cluster-autoscaler -n kube-system
kubectl get pods
kubectl get pods -l app=cluster-autoscaler -n kube-system
kubectl get pods
kubectl get nodes
kubectl get pods
kubectl get nodes
kubectl get pods -o wide
kubectl get nodes
kops get ig
kops edit ig spot-ig
kops update cluster
kops delete ig spot-ig
kops update cluster
kops update cluster --yes
kops get ig
kops rolling-update cluster
ls
kops get ig
kops create ig spot-ig
kops get ig
kops delete ig spot-ig
kops edit ig nodes
kops edit ig nodes-ap-southeast-1a
kops update cluster
kops update cluster --yes
kops rolling-update cluster
kops export kubecfg --admin --kubeconfig ~/workspace/kubeconfig --state=s3://mykubesbucket
kops export kubecfg --admin
kops rolling-update cluster
kops rolling-update cluster --yes
kops get ig
kubectl get pods
ls
cd autoscaler
kops edit ig nodes-ap-southeast-1a
ls
vim cluster-autoscaler-multi-asg.yam
vim cluster-autoscaler-multi-asg.yaml
kubectl apply -f cluster-autoscaler-multi-asg.yaml
kubectl get pods -l app=cluster-autoscaler -n kube-system
kubectl logs -f pod/cluster-autoscaler-769bd8f45b-qdc2x -n kube-system
kubectl get pods
kubectl get nodes
kubectl get pods -o wide
kubectl get servies
kubectl get services
aws iam list-policies | grep ig-policy
kubectl get pods -l app=cluster-autoscaler -n kube-system
vim cluster-autoscaler-multi-asg.yaml
kubectl logs -f pod/cluster-autoscaler-769bd8f45b-qdc2x -n kube-system
aws iam list-policies | grep ig-policy
aws iam attach-role-policy --policy-arn arn:aws:iam::156688359548:policy/ig-policy --role-name nodes-ap-southeast-1a.mykubes.k8s.local
aws iam attach-role-policy --policy-arn arn:aws:iam::156688359548:policy/ig-policy --role-name nodes.mykubes.k8s.local
kubectl apply -f cluster-autoscaler-multi-asg.yaml
kubectl get nodes --show-labels
kubectl get nodes --show-labels | grep disktype
kops get ig
kops edit ig nodes-ap-southeast-1a
kops update cluster
kops update cluster --yes
kops rolling-update cluster 
kops rolling-update cluster  --yes
kubectl get pods
kubectl get nodes
kubectl get pods -o wide
kubectl get services
kubectl get pods
kops get ig
kops edit ig nodes-ap-southeast-1a
ls
vim cluster-autoscaler-multi-asg.yaml
kubectl apply -f cluster-autoscaler-multi-asg.yaml
kubectl get pods -l app=cluster-autoscaler -n kube-system
vim cluster-autoscaler-multi-asg.yaml
kubectl apply -f cluster-autoscaler-multi-asg.yaml
kubectl get pods -l app=cluster-autoscaler -n kube-system
kops logs -f pod/cluster-autoscaler-665f4d69fb-8l49n -n kube-system
kubectl logs -f pod/cluster-autoscaler-665f4d69fb-8l49n -n kube-system
ls
vim ig-policy.json
aws iam create-policy --policy-name nodes-policy --policy-document file://ig-policy.json
aws iam attach-role-policy --policy-arn arn:aws:iam::156688359548:policy/nodes-policy --role-name nodes.mykubes.k8s.local
aws iam attach-role-policy --policy-arn arn:aws:iam::156688359548:policy/nodes-policy --role-name masters.mykubes.k8s.local
aws iam attach-role-policy --policy-arn arn:aws:iam::156688359548:policy/nodes-policy --role-name KubernetesIAMRole
kubectl apply -f cluster-autoscaler-multi-asg.yaml
vim cluster-autoscaler-multi-asg.yaml
kops get ig
vim cluster-autoscaler-multi-asg.yaml
kubectl apply -f cluster-autoscaler-multi-asg.yaml
kubectl get pods -l app=cluster-autoscaler -n kube-system
kubectl get pods
kubectl get services
kubectl get pods -l app=cluster-autoscaler -n kube-system
vim cluster-autoscaler-multi-asg.yaml
ls
cd ..
ls
kubectl get nodes
kubectl logs node ip-172-20-34-23.ap-southeast-1.compute.internal
kubectl get pods
kubectl logs hub-f6df9dd5c-59l88
kubectl get nodes
kubectl get pods
kubectl get nodes
kubectl get pods
kubectl get nodes
kubectl get services
kubectl get pods
kubectl get nodes
kops get ig
kops edit ig nodes-ap-southeast-1a
kops edit ig master-ap-southeast-1a
kops get ig
kops edit ig nodes-ap-southeast-1a
kops create ig spot-ig
kops edit ig nodes-ap-southeast-1a
kops create ig spot-ig
kops edit ig spot-ig
kops edit ig nodes-ap-southeast-1a
kops update cluster
kops update cluster --yes
kops update cluster rolling-update cluster
kops rolling-update cluster
kops rolling-update cluster --yes
kubectl get pods
kubectl get nodes
kubectl get pods -o wide
vim cluster-autoscaler-multi-asg.yaml
cd autoscaler
vim cluster-autoscaler-multi-asg.yaml
kops get ig
vim cluster-autoscaler-multi-asg.yaml
kubectl apply -f cluster-autoscaler-multi-asg.yaml
kubectl get pods -l app=cluster-autoscaler -n kube-system
kubectl logs -f pod/cluster-autoscaler-779bb5b8bb-lr8lh -n kube-system
q
kubectl get pods -l app=cluster-autoscaler -n kube-system
aws iam list-policies | grep ig-policy
aws iam attach-role-policy --policy-arn arn:aws:iam::156688359548:policy/ig-policy --role-name nodes.mykubes.k8s.local
aws iam attach-role-policy --policy-arn arn:aws:iam::156688359548:policy/ig-policy --role-name masters.mykubes.k8s.local
aws iam attach-role-policy --policy-arn arn:aws:iam::156688359548:policy/ig-policy --role-name KubernetesIAMRole
vim cluster-autoscaler-multi-asg.yaml
kubectl apply -f cluster-autoscaler-multi-asg.yaml
kubectl get pods -l app=cluster-autoscaler -n kube-system
kubectl get pods
kubectl get nodes
kubectl get pods -o wide
kubectl get nodes -o wide
kubectl get services
kubectl get pods -o wide
kubectl get nodes -o wide
kubectl get nodes
kubectl get pods -l app=cluster-autoscaler -n kube-system
ls
cd ..
vim configs/config_opt.yaml
kubectl get pods -l app=cluster-autoscaler -n kube-system
kubectl get nodes
kubectl get pods -o wide
vim configs/config_opt.yaml
kubectl get nodes
kubectl get pods -o wide
kubectl get nodes
kubectl get pods -o wide
kubectl get nodes
kops get ig
kops edit ig nodes-ap-southeast-1a
kops edit ig spot-ig
kubectl get pods
kubectl get nodes
kubectl get pods
kubectl get nodes
kops export kubecfg --admin --kubeconfig ~/workspace/kubeconfig --state=s3://mykubesbucket
kops export kubecfg --admin
kubectl get pods
kubectl get nodes
kubectl get services
kubectl get pods -l app=cluster-autoscaler -n kube-system
kubectl get pods 
kubectl get nodes
kubectl get pods -o wide
kops get ig
kops edit ig nodes-ap-southeast-1a
kubectl describe node nodes-ap-southeast-1a
kubectl get nodes
kubectl describe node ip-172-20-41-253.ap-southeast-1.compute.internal
kubectl describe node ip-172-20-41-253.ap-southeast-1.compute.internal | grep Taints
kubectl get nodes
kubectl describe node ip-172-20-50-42.ap-southeast-1.compute.internal | grep Taint
kubectl describe node ip-172-20-43-174.ap-southeast-1.compute.internal | grep Taint
ls
vim configs/config_opt.yaml
clear
ls
vim configs/config_opt.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_opt.yaml
kubectl get pods
kubectl get pods -o wide
kubectl get nodes
vim configs/config_opt.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_opt.yaml
kubectl get pods
kubectl get nodes
kubectl get pods -o wide
kubectl get nodes
kubectl get pods -o wide
kubectl get nodes
netstat -tln
kubectl get pods
kops export kubecfg --admin --kubeconfig ~/workspace/kubeconfig --state=s3://mykubesbucket
kops export kubecfg --admin
kubectl get pods
kops get ig
kubectl get servies
kubectl get services
vim configs/config_opt.yaml
ldap
netstats
netstat 
ls
ls ldif_files
ls
ldapadd
top
ssh ec2-54-151-204-105.ap-southeast-1.compute.amazonaws.com
jupyterhub-ldapauthenticator
ldapwhoami
sudo ldapwhoami -H ldapi:// -Y EXTERNAL -Q
ldapwhoami
ldappasswd -s welcome123 -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -x "uid=user11,ou=user,o=hpc,dc=control,dc=ap-southeast-1,dc=compute,dc=internal"
ldapwhoami
ldapsearch -x -b "uid=user11,dc=ap-southeast-1,ou=groups,dc=compute,dc=internal"
netstat -a
netstat -a | grep ldap
netstat -nlf
netstat -lnt
netstat -lt
vim configs/config_opt.yaml
cat configs/config_opt.yaml
vim configs/config_opt.yaml
nslookup 
ldapsearch uid=admin
ldapsearch uid=user11
ldapsearch -x -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -W uid=user11
vim configs/config_opt.yaml
cp configs/config_opt.yaml configs/config_ldap.yaml
vim configs/ldap.yaml
vim configs/config_ldap.yaml
nslookup
nslookup -type=all _ldap._tcp
nltest /dclist:127.0.0.53#53
nslookup -query=srv _ldap._tcp.127.0.0.53#53
nslookup -query=srv _ldap._tcp.127.0.0.53
ssh ec2-54-251-186-15.ap-southeast-1.compute.amazonaws.com
ldapsearch -x -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -W uid=user11
nslookup -type=srv _ldap._tcp.control.ap-southeast-1.compute.internal
vim configs/config_ldap.yaml
nslookup
vim configs/config_ldap.yaml
nslookup
vim configs/config_ldap.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_ldap.yaml
kubectl get pods
kubectl get nodes
kubectl get services
ls
ls ldif_files
vim ldif_files/user11.ldif
vim ldif_files/user2.ldif
vim ldif_files/user22.ldif
kubectl get pods
kubectl logs hub-594674cb58-m6nlx
vim configs/confi_ldap.yaml
openssl s_client -connect HOST:PORTopenssl s_client -connect HOST:PORT
openssl s_client -connect HOST:PORT
vim configs/config_ldap.yaml
cat /etc/ldap.conf
ls ldap
ls
ls ldif_files
cat ldif_files/user11.ldif
cat ldif_files/o.ldif
cat ldif_files/user44.ldif
ls ldif_files
ls
ldapsearch -x -h control.ap-southeast-1.compute.internal -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -W uid=user11
ldapsearch -x -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -W uid=user11
openssl s_client -connect HOST:PORT
vim configs/config_ldap.yaml
ls
vim configs/config_ldap.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_ldap.yaml
kubectl get pods
kubectl get services
kubectl logs hub-5896c97898-l96dh
kubectl get services
ldapsearch -x -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -W uid=user11
ldapsearch -x -LLL uid=*
ldappasswd -s welcome123 -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -x "uid=user22,ou=user,o=hpc,dc=control,dc=ap-southeast-1,dc=compute,dc=internal"
ldappasswd -s welcome123 -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -x "uid=user11,ou=user,o=hpc,dc=control,dc=ap-southeast-1,dc=compute,dc=internal"
kubectl get services
kubectl get pods
kops logs hub-5896c97898-l96dh
kubectl logs hub-5896c97898-l96dh
vim configs/config_ldap.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_ldap.yaml
kubectl get pods
vim configs/config_ldap.yaml
cat configs/config_ldap.yaml
vim configs/config_ldap.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_ldap.yaml
kubectl get pods
kubectl get services
kubectl logs hub-57f9d77f97-h8r6p
ldapsearch -x -LLL uid=*
ldapadd -x -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -f user9.ldif
ls
cd ldif_files
ls
cp user11.ldfi user9.ldif
cp user11.ldif user9.ldif
vim user9.ldif
ldapadd -x -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -f user9.ldif
ldappasswd -s welcome123 -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -x "uid=user9,ou=user,o=hpc,dc=control,dc=ap-southeast-1,dc=compute,dc=internal"
kubectl get services
vim configs/config_ldap.yaml
cd ..
vim configs/config_ldap.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_ldap.yaml
kubectl get pods
kubectl get services
vim configs/config_ldap.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_ldap.yaml
kubectl get pods
kubectl get services
kubectl logs hub-659d847cfb-d7jc2
vim configs/config_ldap.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_ldap.yaml
kubectl get pods
kubectl logs hub-7b7ccbbbb4-zxkvf
kubectl get pods
kubectl get services
kubectl get pods
kubectl logs hub-7b7ccbbbb4-zxkvf
vim configs/config_ldap.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_ldap.yaml
kubectl get pods
kubectl logs hub-d67f59466-rnh4z
ldapsearch -x -LLL uid=*
vim configs/config_ldap.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_ldap.yaml
kubectl get pods 
kubectl logs hub-bdc44c87f-zrqdc
vim configs/config_ldap.yaml
ldapsearch -x -LLL uid=*
vim configs/config_ldap.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_ldap.yaml
kubectl get pods
kubectl get services
kubectl logs hub-d6c68c7bd-4rhjd
pip install jupyterhub-ldapauthenticator
python -v
python --version
sudo apt update -y
sudo apt install python3.7
pip install jupyterhub-ldapauthenticator
ssh ec2-54-179-6-165.ap-southeast-1.compute.amazonaws.com
python --version]
python --version
python3 --version]
python3 --version
exit
pip3 install jupyterhub-ldapauthenticator
sudo apt install python3-pip
pip3 install jupyterhub-ldapauthenticator
sudo apt get upgrade pip3
sudo apt upgrade pip3
sudo apt upgrade python3-pip
pip3 install jupyterhub-ldapauthenticator
pip3 install --upgrade pip
pip3 install jupyterhub-ldapauthenticator
vim configs/config_ldap.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_ldap.yaml
kubectl get pods
kubectl get nodes
kubectl get services
top
kubectl get nodes
kubectl get services
kubectl get pods
kubectl logs hub-bdc44c87f-b5vpw
vim configs/config_ldap.yaml
kubectl get pods
kubectl logs hub-bdc44c87f-b5vpw
kubectl get nodes
ssh ec2-54-151-204-105.ap-southeast-1.compute.amazonaws.com
ls
ldapsearch -x -LLL uid=*
netstat -ltn
kubectl get pods
vim configs/config_ldap.yaml
ssh ec2-54-151-204-105.ap-southeast-1.compute.amazonaws.com
vim configs/config_ldap.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_ldap.yaml
kubectl get pods
kubectl get services
kubectl logs hub-bdc44c87f-b5vpw
ls
vim configs/config_ldap.yaml
ls
kubectl get pods
kubectl get nodes
ls
vim configs/config_ldap.yaml
kubectl get pods
kops export kubecfg --admin --kubeconfig ~/workspace/kubeconfig --state=s3://mykubesbucket
kops export kubecfg --admin
kubectl get pods
kubectl get nodes
kubectl get pods -o wide
vim configs/config_ldap.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_ldap.yaml
kubectl get pods
kubectl logs hub-68668d747-f45fw
kubectl get services
kubectl logs hub-68668d747-f45fw
netstat -tln
ssh ec2-54-151-204-105.ap-southeast-1.compute.amazonaws.com
ldapsearch -x -LLL uid=*
ssh ec2-54-151-204-105.ap-southeast-1.compute.amazonaws.com
kubectl get pods
kubectl logs hub-68668d747-f45fw
vim configs/config_ldap.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_ldap.yaml
kubectl get pods
kubectl get services
kubectl logs hub-bdc44c87f-58jp6
vim configs/config_ldap.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_ldap.yaml
kubectl get pods
kubectl get services
kubectl logs hub-cfdd648b6-6c882
vim configs/config_ldap.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_ldap.yaml
kubectl get pods
kubectl get services
kubectl logs hub-69bb69b59-727tl
vim configs/config_ldap.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_ldap.yaml
kubectl get pods
kubectl get services
kubectl logs hub-5579c77488-4ftmc
vim configs/config_ldap.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_ldap.yaml
kubectl get pods
kubectl get services
kubectl get pods
kubectl logs hub-65548ccd45-k2nd9
helm history jhub -n jhub --kube-context mykubes.k8s.local
ldap
ls
ls /etc
ls /etc/ldap
vim /etc/ldap/ldap.conf
ldapsearch --version
ldapsearch 
/usr/sbin/slapd -VV
ls /etc/ldap
ldapsearch -VV
ldapsearch -V
openlldap
openldap
ldap
ldapp
ldapsearch -v
/usr/bin/ldapserach -VV
ls 
ls /etc/sldap
/usr/sbin/slapd -VV
ls /usr/sbin/slapd
/usr/sbin/slapd
ls /etc/ldap
vim /etc/ldap/ldap.conf
tree /etc/ldap
ls /etc/ldap/schema
vim /etc/ldap/schema/README
cd /usr/sbin
ls
cd slapd
slapd
slapd -VV
dpkg -s slapd | grep Version
kubectl get pods
kubectl logs hub-65548ccd45-k2nd9
kubectl get services
kubectl get pods
kubectl logs hub-65548ccd45-k2nd9
kubectl get pods
kubectl get services
vim configs/config_ldap.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_ldap.yaml
kubectl get pods
kubectl get services
kubectl logs hub-bdc44c87f-5f5ww
ls
ls /etc/ldap
vim /etc/ldap/ldap.conf
ls
ssh ec2-54-151-204-105.ap-southeast-1.compute.amazonaws.com
ls
ls jhubCert
cd /var/myca
CA.sh
ls /etc
ls /etc/openssl
openssl
ls /usr
ls /usr/local
ls /usr/bin
ls /usr/bin/openssl
ls
openldap
ldap
sudo apt install openldap
ls /etc/pki/CA
ldapadd
ssh ec2-54-251-186-15.ap-southeast-1.compute.amazonaws.com
ssh ec2-54-151-204-105.ap-southeast-1.compute.amazonaws.com
ls
ls ldif_files
vim ou_grp.ldif
cd ldif_files
vim ou_grp.ldif
vim group1.ldif
vim ou_grp.ldif
vim group1.ldif
ldapsearch -x -LLL uid=*
ssh ec2-54-151-204-105.ap-southeast-1.compute.amazonaws.com
exit
ls
ssh ec2-54-151-204-105.ap-southeast-1.compute.amazonaws.com
ls
vim configs/config_ldap.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_ldap.yaml
kubectl get pods
kubectl get services
kubectl logs hub-76f5955c78-cw956
ls
vim configs/config_ldap.yaml
kubectl get nodes
ssh ec2-54-151-204-105.ap-southeast-1.compute.amazonaws.com
ec2-54-251-186-15.ap-southeast-1.compute.amazonaws.com
ssh ec2-54-251-186-15.ap-southeast-1.compute.amazonaws.com
ssh ec2-54-151-204-105.ap-southeast-1.compute.amazonaws.com
vim configs/config_ldap.yaml
ldapsearch -h ec2-54-151-204-105.ap-southeast-1.compute.amazonaws.com -b "dc=ap-southeast-1,dc=compute,dc=internal" -x
ssh ec2-54-251-186-15.ap-southeast-1.compute.amazonaws.com
ls
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values config.yaml
cd jhub
ls
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_ldap.yaml
kubectl get pods
kubectl get services
kubectl get pods
ls
ldapsearch -x -LLL -b "" -s base namingContexts
ldapsearch -H ldapi:/// -Y EXTERNAL -b "cn=config" -LLL -Q | grep olcRootDN:
sudo ldapsearch -H ldapi:/// -Y EXTERNAL -b "cn=config" -LLL -Q | grep olcRootDN:
sudo ldapsearch -H ldapi:/// -Y EXTERNAL -b "cn=config" -LLL -Q | grep olcLogLevel:
sudo -i
ls
vim configs/config_ldap.yaml
ls
vim configs/config_ldap.yaml
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values configs/config_ldap.yaml
kubectl get pods
kubectl get services
kubectl get pods
kubectl logs hub-bdc44c87f-fcz56
exit
kubectl describe pvc hostpath
kubectl get pvc
kubectl describe pvc hub-db-dir
kubectl describe pvc claim-user11
kubectl get pv
kubectl get pvc
ls
ls workspace
vim workspace/kubeconfig
ls
ls /etc
ls ~
ls /
ls /mnt
ls /mnt/nfs_share
ssh ec2-54-251-186-15.ap-southeast-1.compute.amazonaws.com
ssh ec2-54-151-204-105.ap-southeast-1.compute.amazonaws.com
ls /mnt
ls
ls /etc/exports
ls
ls /etc/
ls /etc/exports
sudo ls /etc/exports
vim /etc/exports
top
exit
ec2-54-251-186-15.ap-southeast-1.compute.amazonaws.com
ssh ec2-54-251-186-15.ap-southeast-1.compute.amazonaws.co
ssh ec2-54-151-204-105.ap-southeast-1.compute.amazonaws.com
ls /etc/exports
vim /etc/exports
ssh ec2-54-251-186-15.ap-southeast-1.compute.amazonaws.com
exportfs -a
sudo exportfs -a
vim /etc/exports
sudo vim /etc/exports
ls
exportfs -a
sudo exportfs -a
/home
cat /etc/exports
ssh ec2-54-251-186-15.ap-southeast-1.compute.amazonaws.com
nfs
nfsserver
passwd ubuntu
sudo passwd ubuntu
ps
top
ls
ssh ec2-54-251-186-15.ap-southeast-1.compute.amazonaws.com
ls
kubectl get pods
kops export kubecfg --admin --kubeconfig ~/workspace/kubeconfig --state=s3://mykubesbucket
kops export kubecfg --admin
kubectl get pods
kubectl get services
kubectl get storageclass
kubectl get pvc
ls
kubectl get storageclass
kubectl get pv
kubectl get pvc
ls
vim pod.yaml
ls workspace
vim workspace/kubeconfig
df -h
sudo apt update
sudo apt install nfs-common
sudo yum install nfs-utils
sudo apt install nfs-utils
sudo apt install yum
sudo yum install nfs-utils
yun repolist all
yum repolist all
sudo apt install deb yum
yun-config-manager --enable 
yum-config-manager --enable 
sudo apt install yum-utils
yum install nfs-utils
sudo yum install nfs-utils
yum-config-manager --enable
sudo yum-config-manager --enable
nfs-utils
apt-get install nfs-utils nfs-utils-lib
sudo apt-get install nfs-utils
sudo apt-get update
sudo apt-get install nfs-utils
sudo apt-get upgrade
sudo apt-get install nfs-utils
lsb_release -a
sudo apt-get update
sudo apt install nfs-kernel-server
ls
ls /mnt
ls /mnt/nfs_share
sudo chown nobody:nogroup /mnt/nfs_share
sudo chmod 777 /mnt/nfs_share
ls -l /mnt
sudo vim /etc/exports
sudo exportfs -a
sudo systemctl restart nfs-kernel-server
sudo ufw allow from ec2-54-251-186-15.ap-southeast-1.compute.amazonaws.com to any port nfs
sudo ufw allow from ec2-54-251-186-15.ap-southeast-1.compute.amazonaws.com
nslookup ec2-54-251-186-15.ap-southeast-1.compute.amazonaws.com
sudo ufw allow from 54.251.186.15 to any port nfs
nslookup ec2-54-151-204-105.ap-southeast-1.compute.amazonaws.com
sudo ufw allow from 54.151.204.105 to any port nfs
sudo ufw status
sudo ufw enable
sudo ufw default deny
sudo iptables -L
sudo ufw status
ssh ec2-54-251-186-15.ap-southeast-1.compute.amazonaws.com
ls
ls /mnt/nfs_share
kops export kubecfg --admin --kubeconfig ~/workspace/kubeconfig --state=s3://mykubesbucket
kops export kubecfg --admin
kubectl --namespace=jhub get pod
ls
cat config_multi.yaml 
emacs
nano config_multi.yaml 
ls
nano config_multi_dummy.yaml 
helm list
history | grep helm
helm list --all-namespaces -a
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi_dummy.yaml --debug
kubectl --namespace=jhub get svc proxy-public
nano config_multi_dummy.yaml 
ls
cat config_multi_dummy.yaml 
nano config_multi_dummy.yaml 
helm list --all-namespaces -a
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.7 --values config_multi_dummy.yaml --debug
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.10.6 --values config_multi_dummy.yaml --debug
kubectl --namespace=jhub get svc proxy-public
kubectl --namespace=jhub get pod
ls
cat config_multi_dummy.yaml 
helm upgrade --cleanup-on-fail  jhub jupyterhub/jupyterhub   --namespace jhub  --version=0.11.1 --values config_multi_dummy.yaml 
kubectl --namespace=jhub get pod
cat /etc/passwd
ls
cd configs
ls
cat config_multi_pam.yaml 
ssh user1@ec2-13-250-54-242.ap-southeast-1.compute.amazonaws.com
ssh ec2-13-250-54-242.ap-southeast-1.compute.amazonaws.com
ls
nano config_multi_pam.yaml 
kubectl --namespace jhub logs hub-5cbdc74bc5-nz6x8
ls
nano config_multi_pam.yaml 
kubectl --namespace jhub logs hub-5cbdc74bc5-nz6x8
ls
cat config_multi_pam.yaml 
kubectl --namespace jhub logs hub-5cbdc74bc5-nz6x8
kubectl --namespace=jhub get pod
kubectl --namespace jhub logs hub-888688664-sxf4b
ls
sudo apt install slapd ldap-utils
sudo dpkg-reconfigure slapd
netstat -tln
ldapsearch -H ldap://127.0.0.1
ldapsearch -H ldap://
ldapsearch -H ldap:// -x
ldapsearch -H ldap://server_domain_or_IP -x -LLL -s base -b "" namingContexts
ldapsearch -H ldap:// -x -LLL -s base -b "" namingContexts
ldapsearch -H ldap:// -x -LLL -s base -b "namingContexts: dc=control,dc=ap-southeast-1,dc=compute,dc=internal" namingContexts
ldapsearch -H ldap:// -x -LLL -s base -b "dc=control,dc=ap-southeast-1,dc=compute,dc=internal" namingContexts
ldapsearch -H ldap://server_domain_or_IP -x -LLL -b "dc=example,dc=com" "(objectClass=simpleSecurityObject)" dn
ldapsearch -H ldap:// -x -LLL -s base -b "dc=control,dc=ap-southeast-1,dc=compute,dc=internal" "(objectClass=simpleSecurityObject)" dn
ldapsearch -H ldap:// -x -LLL -s base -b "dc=control,dc=ap-southeast-1,dc=compute,dc=internal" "(objectClass=simpleSecurityObject)" 
ldapsearch -H ldap:// -x -LLL -s base -b "dc=control,dc=ap-southeast-1,dc=compute,dc=internal" 
ldapsearch -x -b '' -s base
ldapsearch -H ldap:// -x -s base -b "" -LLL "+"
ldapsearch -H ldap:// -x -s base -b "" -LLL "configContext"
sudo ldapsearch -H ldapi:// -Y EXTERNAL -b "cn=config" -LLL -Q
sudo ldapsearch -H ldapi:// -Y EXTERNAL -b "cn=config" "(olcRootDN=*)" olcSuffix olcRootDN olcRootPW -LLL -Q
cat /etc/openldap
ls /etc
ls /etc/ldap/slapd.d/
ls /etc/ldap
nano /etc/ldap/ldap.conf 
ldapsearch -x -w 4dminp455w0rd
cd
nano .ldaprc
ldapsearch -x -w 
ldapsearch -x 
ldapsearch -H ldap:// -x -D "cb=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -W
ldapsearch -x -D "cb=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -W
ldapsearch -x -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -W
mkdir ldif_files
cd ldif_files/
nano user1.ldif
ldapadd -x -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -f user1.ldif 
nano ou.ldif
ldapadd -x -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -f ou.ldif 
cat ou.ldif 
nano ou.ldif 
ldapadd -x -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -f ou.ldif 
nano ou.ldif 
ldapadd -x -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -f ou.ldif 
cp ou.ldif o.ldif
nano o.ldif 
ldapadd -x -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -f o.ldif 
nano o.ldif 
ldapadd -x -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -f o.ldif 
nano ou.ldif 
ldapadd -x -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -f ou.ldif 
ls
nano user1.ldif 
ldapadd -x -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -f user1.ldif 
nano user1.ldif 
ldapadd -x -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -f user1.ldif 
ldappasswd -s welcome123 -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -x "uid=user11,ou=user,dc=control,dc=ap-southeast-1,dc=compute,dc=internal"
ldappasswd -s welcome123 -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -x "uid=user11,ou=user,o=hpc,dc=control,dc=ap-southeast-1,dc=compute,dc=internal"
cat user1.ldif 
cat ou.ldif ]
cat o.ldif 
ls
mv user1.ldif user11.ldif
cp user11.ldif user22.ldif
nano user22.ldif
ldapadd -x -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -f user22.ldif 
ldappasswd -s welcome123 -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -x "uid=user22,ou=user,o=hpc,dc=control,dc=ap-southeast-1,dc=compute,dc=internal"
ldapsearch -x -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -W
netstat -tln
nano group1.ldif
ldapadd -x -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -f group1.ldif 
ls
cp ou.ldif ou_grp.ldif
nano ou_grp.ldif 
ldapadd -x -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -f ou_grp.ldif 
ldapadd -x -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -f group1.ldif 
nano group1.ldif 
ldapsearch -x -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -W
ls
cat ou.ldif 
nano group1.ldif 
nano ou_grp.ldif 
ldapadd -x -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -f group1.ldif 
nano ou_grp.ldif 
nano group1.ldif 
ldapadd -x -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -f group1.ldif 
cat group1.ldif 
ls
cp user22.ldif user33.ldif
nano user33.ldif 
ldapadd -x -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -f user33.ldif 
ldappasswd -s welcome123 -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -x "uid=user33,ou=user,o=hpc,dc=control,dc=ap-southeast-1,dc=compute,dc=internal"
cp user33.ldif user44.ldif
nano user44.ldif 
cp user33.ldif user55.ldif
nano user55.ldif 
ldapadd -x -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -f user44.ldif 
ldapadd -x -W -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -f user55.ldif 
netstat -tln
ldapsearch uid=user11
history | grep ldapsearch
ldapsearch -x -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -W
ldapsearch -x -D "cn=admin,dc=control,dc=ap-southeast-1,dc=compute,dc=internal" -W uid=user11
cd
history | grep ssh
ifconfig
ssh ec2-54-151-204-105.ap-southeast-1.compute.amazonaws.com
history | grep ldapsearch
ssh ec2-54-151-204-105.ap-southeast-1.compute.amazonaws.com
